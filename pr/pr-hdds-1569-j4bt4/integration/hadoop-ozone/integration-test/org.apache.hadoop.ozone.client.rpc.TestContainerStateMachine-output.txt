2019-09-19 08:51:09,575 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:09,687 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:09,690 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:09,708 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2859ms
2019-09-19 08:51:09,820 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-09-19 08:51:09,820 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-09-19 08:51:09,821 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-09-19 08:51:09,821 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-09-19 08:51:09,821 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-09-19 08:51:09,821 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-09-19 08:51:09,836 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:51:09,836 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:51:09,837 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:51:10,053 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@773f7880
2019-09-19 08:51:10,055 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-09-19 08:51:10,124 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(121)) - Entering startup safe mode.
2019-09-19 08:51:10,143 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(56)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2019-09-19 08:51:10,157 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:10,200 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-09-19 08:51:10,202 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:10,325 [main] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-09-19 08:51:10,421 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:51:10,448 [Socket Reader #1 for port 33464] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33464
2019-09-19 08:51:10,469 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:51:10,470 [Socket Reader #1 for port 34951] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34951
2019-09-19 08:51:10,477 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:51:10,478 [Socket Reader #1 for port 42725] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42725
2019-09-19 08:51:10,497 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-09-19 08:51:10,626 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:51:10,634 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:51:10,642 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:51:10,644 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-09-19 08:51:10,644 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:51:10,645 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:51:10,674 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(759)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42725
2019-09-19 08:51:10,739 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-09-19 08:51:10,751 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-09-19 08:51:10,752 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-09-19 08:51:10,792 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(151)) - RPC server for Client  is listening at /0.0.0.0:42725
2019-09-19 08:51:10,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:51:10,793 [IPC Server listener on 42725] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42725: starting
2019-09-19 08:51:10,796 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(769)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34951
2019-09-19 08:51:10,796 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(140)) - RPC server for Block Protocol is listening at /0.0.0.0:34951
2019-09-19 08:51:10,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:51:10,796 [IPC Server listener on 34951] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34951: starting
2019-09-19 08:51:10,798 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33464
2019-09-19 08:51:10,799 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33464
2019-09-19 08:51:10,799 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:51:10,799 [IPC Server listener on 33464] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33464: starting
2019-09-19 08:51:10,803 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45425
2019-09-19 08:51:10,804 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:51:10,860 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b1637e1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:51:10,860 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64711bf2{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:51:10,901 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68e62ca4{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{/scm}
2019-09-19 08:51:10,907 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d4960c8{HTTP/1.1,[http/1.1]}{0.0.0.0:45425}
2019-09-19 08:51:10,907 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4059ms
2019-09-19 08:51:10,909 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of SCM is listening at http://0.0.0.0:45425
2019-09-19 08:51:10,919 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@588ffeb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:51:10,925 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:10,940 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:10,941 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:10,943 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(645)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-09-19 08:51:10,944 [main] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(651)) - OM Node ID is not set. Setting it to the OmStorage's OmID: c30add40-b303-4c3f-950d-e4ec687cb28b
2019-09-19 08:51:10,946 [main] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(602)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-09-19 08:51:11,125 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(222)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-09-19 08:51:11,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-09-19 08:51:11,136 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-09-19 08:51:11,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-09-19 08:51:11,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-09-19 08:51:11,137 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-09-19 08:51:11,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-09-19 08:51:11,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-09-19 08:51:11,138 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-09-19 08:51:11,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-09-19 08:51:11,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-09-19 08:51:11,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-09-19 08:51:11,139 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-09-19 08:51:11,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-09-19 08:51:11,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-09-19 08:51:11,140 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-09-19 08:51:11,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-09-19 08:51:11,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-09-19 08:51:11,141 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-09-19 08:51:11,142 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-09-19 08:51:11,142 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-09-19 08:51:11,142 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-09-19 08:51:11,142 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-09-19 08:51:11,143 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-09-19 08:51:11,143 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-09-19 08:51:11,143 [main] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-09-19 08:51:11,646 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-09-19 08:51:11,647 [Socket Reader #1 for port 34400] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34400
2019-09-19 08:51:11,668 [main] INFO  om.OzoneManager (OzoneManager.java:start(1256)) - OzoneManager RPC server is listening at localhost/127.0.0.1:34400
2019-09-19 08:51:11,668 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-09-19 08:51:11,670 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-09-19 08:51:11,670 [IPC Server listener on 34400] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34400: starting
2019-09-19 08:51:11,675 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-09-19 08:51:11,679 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:51:11,681 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:51:11,685 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:51:11,686 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-09-19 08:51:11,686 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:51:11,687 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:51:11,690 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34439
2019-09-19 08:51:11,691 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:51:11,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f92c349{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:51:11,695 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55f8669d{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2019-09-19 08:51:11,703 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48c3205a{/,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-09-19 08:51:11,704 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@121c54fa{HTTP/1.1,[http/1.1]}{0.0.0.0:34439}
2019-09-19 08:51:11,705 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4856ms
2019-09-19 08:51:11,706 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:34439
2019-09-19 08:51:11,996 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-09-19 08:51:12,085 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(184)) - HddsDatanodeService host:pr-hdds-1569-j4bt4-3030777008 ip:192.168.34.5
2019-09-19 08:51:12,123 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 1482555576320
2019-09-19 08:51:12,125 [main] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/containers/hdds to VolumeSet
2019-09-19 08:51:12,127 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@15e0fe05
2019-09-19 08:51:12,144 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@15e0fe05
2019-09-19 08:51:12,266 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-09-19 08:51:12,334 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2019-09-19 08:51:12,339 [main] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 0 (default)
2019-09-19 08:51:12,341 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-09-19 08:51:12,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:51:12,343 [main] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-09-19 08:51:12,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-09-19 08:51:12,476 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis] (custom)
2019-09-19 08:51:12,508 [main] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-09-19 08:51:12,520 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-09-19 08:51:12,522 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-19 08:51:12,523 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-09-19 08:51:12,525 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-19 08:51:12,526 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-09-19 08:51:12,526 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-19 08:51:12,526 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-19 08:51:12,527 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38756
2019-09-19 08:51:12,527 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-09-19 08:51:12,530 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6edf29c1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,AVAILABLE}
2019-09-19 08:51:12,530 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66b59b7d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2019-09-19 08:51:12,572 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a08efdc{/,file:///tmp/jetty-0.0.0.0-38756-hddsDatanode-_-any-178321133647870813.dir/webapp/,AVAILABLE}{/hddsDatanode}
2019-09-19 08:51:12,573 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@57272109{HTTP/1.1,[http/1.1]}{0.0.0.0:38756}
2019-09-19 08:51:12,574 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5725ms
2019-09-19 08:51:12,575 [main] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(213)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38756
Sep 19, 2019 8:51:12 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-09-19 08:51:13,790 | INFO  | ObjectStoreRestHttpServer | Listening HDDS REST traffic on /0.0.0.0:34627 |  
2019-09-19 08:51:13,799 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(395)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@57fdb8a4
2019-09-19 08:51:13,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-19 08:51:13,805 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e24191] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-09-19 08:51:13,889 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/meta/datanode.id
2019-09-19 08:51:14,802 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-19 08:51:15,803 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-19 08:51:16,003 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=GET_VERSION null | ret=SUCCESS |  
2019-09-19 08:51:16,031 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-09-19 08:51:16,033 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-09-19 08:51:16,033 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(404)) - Starting XceiverServerRatis e9620dcf-fbb8-43dd-90df-6386dfe78fe1 at port 0
2019-09-19 08:51:16,058 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: start RPC server
2019-09-19 08:51:16,198 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(149)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: GrpcService started, listening on 0.0.0.0/0.0.0.0:36578
2019-09-19 08:51:16,199 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(414)) - XceiverServerRatis e9620dcf-fbb8-43dd-90df-6386dfe78fe1 is started using port 36578
2019-09-19 08:51:16,200 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(163)) - XceiverServerGrpc e9620dcf-fbb8-43dd-90df-6386dfe78fe1 is started using port 43500
2019-09-19 08:51:16,804 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-19 08:51:17,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 1 DN Heartbeats.
2019-09-19 08:51:17,846 [IPC Server handler 18 on 33464] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(110)) - Added a new node: /default-rack/e9620dcf-fbb8-43dd-90df-6386dfe78fe1
2019-09-19 08:51:17,847 [IPC Server handler 18 on 33464] INFO  node.SCMNodeManager (SCMNodeManager.java:register(273)) - Registered Data node : e9620dcf-fbb8-43dd-90df-6386dfe78fe1{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}
2019-09-19 08:51:17,851 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-09-19 08:51:17,851 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-09-19 08:51:17,851 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-09-19 08:51:17,856 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=REGISTER {datanodeDetails=e9620dcf-fbb8-43dd-90df-6386dfe78fe1{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null}} | ret=SUCCESS |  
2019-09-19 08:51:18,772 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: addNew group-0C305E2DA083:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] returns group-0C305E2DA083:java.util.concurrent.CompletableFuture@410b8dc9[Not completed]
2019-09-19 08:51:18,790 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: new RaftServerImpl for group-0C305E2DA083:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] with ContainerStateMachine:uninitialized
2019-09-19 08:51:18,793 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:51:18,794 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:51:18,794 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:51:18,796 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:51:18,797 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:51:18,805 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 1 of 1 DN Heartbeats.
2019-09-19 08:51:18,806 [main] INFO  om.OzoneManager (OzoneManager.java:readKeyPair(880)) - Reading keypair and certificate from file system.
2019-09-19 08:51:18,806 [main] INFO  om.OzoneManager (OzoneManager.java:startSecretManager(846)) - Starting OM block token secret manager
2019-09-19 08:51:18,807 [main] INFO  security.OzoneBlockTokenSecretManager (OzoneSecretManager.java:updateCurrentKey(167)) - Updating the current master key for generating tokens
2019-09-19 08:51:18,807 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1:group-0C305E2DA083 ConfigurationManager, init=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null, confs=<EMPTY_MAP>
2019-09-19 08:51:18,807 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis] (custom)
2019-09-19 08:51:18,817 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083 does not exist. Creating ...
2019-09-19 08:51:19,140 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(293)) - Creating Volume: testcontainerstatemachinefailures, with jenkins1000 as owner.
2019-09-19 08:51:19,163 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_VOLUME {admin=jenkins1000, owner=jenkins1000, volume=testcontainerstatemachinefailures, creationTime=1568883079158, quotaInBytes=1152921504606846976} | ret=SUCCESS |  
2019-09-19 08:51:19,174 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=testcontainerstatemachinefailures} | ret=SUCCESS |  
2019-09-19 08:51:19,179 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(432)) - Creating Bucket: testcontainerstatemachinefailures/testcontainerstatemachinefailures, with Versioning false and Storage Type set to DISK and Encryption set to false 
2019-09-19 08:51:19,195 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=CREATE_BUCKET {volume=testcontainerstatemachinefailures, bucket=testcontainerstatemachinefailures, acls=[user:jenkins1000:a[ACCESS], group:default:a[ACCESS]], isVersionEnabled=false, storageType=DISK, creationTime=0} | ret=SUCCESS |  
2019-09-19 08:51:19,201 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_VOLUME {volume=testcontainerstatemachinefailures} | ret=SUCCESS |  
2019-09-19 08:51:19,206 | INFO  | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=READ_BUCKET {volume=testcontainerstatemachinefailures, bucket=testcontainerstatemachinefailures} | ret=SUCCESS |  
2019-09-19 08:51:19,846 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,008 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,407 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,613 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:20,854 [Thread-146] INFO  container.ReplicationManager (ReplicationManager.java:start(151)) - Starting Replication Monitor Thread.
2019-09-19 08:51:20,857 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(214)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2019-09-19 08:51:21,009 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:21,069 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$2(182)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@785dfbfa for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2957085762ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:169)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:138)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:279)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:206)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$1(RatisPipelineProvider.java:141)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$2(RatisPipelineProvider.java:178)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$3(RatisPipelineProvider.java:172)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2957085762ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:140)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:167)
	... 25 more
2019-09-19 08:51:21,074 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@785dfbfa for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
2019-09-19 08:51:21,075 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(129)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:51:21,076 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:51:21,109 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: addNew group-F279671BCF98:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] returns group-F279671BCF98:java.util.concurrent.CompletableFuture@4ba7f52f[Not completed]
2019-09-19 08:51:21,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:21,413 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:21,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:21,809 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:22,009 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:22,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:22,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:22,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:22,808 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:23,009 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:23,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:23,408 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:23,612 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:23,809 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:24,008 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:24,089 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$2(182)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@383af1c3 for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999661748ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:169)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:138)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:279)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:206)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$1(RatisPipelineProvider.java:141)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$2(RatisPipelineProvider.java:178)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$3(RatisPipelineProvider.java:172)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999661748ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:140)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:167)
	... 25 more
2019-09-19 08:51:24,093 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@383af1c3 for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
2019-09-19 08:51:24,093 [RatisPipelineUtilsThread] ERROR pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(129)) - Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:51:24,094 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Not enough healthy nodes to allocate pipeline. 3  datanodes required. Found 1
2019-09-19 08:51:24,109 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: addNew group-AE48826E6C11:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] returns group-AE48826E6C11:java.util.concurrent.CompletableFuture@2bd983ff[Not completed]
2019-09-19 08:51:24,208 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:24,409 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:24,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:24,809 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:25,008 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:25,209 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:25,413 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:25,608 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:25,809 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:26,009 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:26,210 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:26,410 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:26,609 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:26,809 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:27,009 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=SEND_HEARTBEAT {datanodeUUID=e9620dcf-fbb8-43dd-90df-6386dfe78fe1, command=[]} | ret=SUCCESS |  
2019-09-19 08:51:27,102 [RATISCREATEPIPELINE1] ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$2(182)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@498a8982 for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999676474ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:169)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:138)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:279)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:206)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$1(RatisPipelineProvider.java:141)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$2(RatisPipelineProvider.java:178)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$3(RatisPipelineProvider.java:172)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999676474ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:140)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:167)
	... 25 more
2019-09-19 08:51:27,105 [IPC Server handler 12 on 34951] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(161)) - Pipeline creation failed due to exception: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@498a8982 for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
2019-09-19 08:51:27,105 [IPC Server handler 12 on 34951] WARN  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(192)) - Pipeline creation failed for type:RATIS factor:ONE. Retrying get pipelines call once.
java.io.IOException: Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$167/1171286313@498a8982 for e9620dcf-fbb8-43dd-90df-6386dfe78fe1
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$2(RatisPipelineProvider.java:183)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$3(RatisPipelineProvider.java:172)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
Caused by: org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2999676474ns
	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:82)
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:75)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:169)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:138)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:94)
	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:279)
	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:206)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$1(RatisPipelineProvider.java:141)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$2(RatisPipelineProvider.java:178)
	... 19 more
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2999676474ns
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:233)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:214)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:139)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:274)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:140)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:167)
	... 25 more
2019-09-19 08:51:27,107 [IPC Server handler 12 on 34951] INFO  block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(198)) - Could not find available pipeline of type:RATIS and factor:ONE even after retrying
2019-09-19 08:51:27,108 [IPC Server handler 12 on 34951] ERROR block.BlockManagerImpl (BlockManagerImpl.java:allocateBlock(222)) - Unable to allocate a block for the size: 4194304, type: RATIS, factor: ONE
2019-09-19 08:51:27,108 | INFO  | SCMAudit | user=jenkins1000 | ip=192.168.34.5 | op=ALLOCATE_BLOCK {owner=c30add40-b303-4c3f-950d-e4ec687cb28b, size=4194304, type=RATIS, factor=ONE} | ret=SUCCESS |  
2019-09-19 08:51:27,114 | ERROR | OMAudit | user=jenkins1000 | ip=127.0.0.1 | op=ALLOCATE_KEY {volume=testcontainerstatemachinefailures, bucket=testcontainerstatemachinefailures, key=ratis, dataSize=1024, replicationType=RATIS, replicationFactor=ONE, keyLocationInfo=null} | ret=FAILURE | org.apache.hadoop.hdds.scm.exceptions.SCMException: Allocated 0 blocks. Requested 1 blocks
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.handleError(ScmBlockLocationProtocolClientSideTranslatorPB.java:118)
	at org.apache.hadoop.hdds.scm.protocolPB.ScmBlockLocationProtocolClientSideTranslatorPB.allocateBlock(ScmBlockLocationProtocolClientSideTranslatorPB.java:156) 
2019-09-19 08:51:27,130 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-09-19 08:51:27,131 | INFO  | SCMAudit | user=null | ip=null | op=GET_SCM_INFO null | ret=SUCCESS |  
2019-09-19 08:51:27,131 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-09-19 08:51:27,131 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-09-19 08:51:27,131 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34400
2019-09-19 08:51:27,138 [IPC Server listener on 34400] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34400
2019-09-19 08:51:27,140 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(248)) - Stopping OMDoubleBuffer flush thread
2019-09-19 08:51:27,142 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:51:27,144 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(191)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2019-09-19 08:51:27,148 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-09-19 08:51:27,150 [main] INFO  om.OzoneManager (OzoneManager.java:stopSecretManager(818)) - Stopping OM block token manager.
2019-09-19 08:51:27,153 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48c3205a{/,null,UNAVAILABLE}{/ozoneManager}
2019-09-19 08:51:27,159 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@121c54fa{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:51:27,160 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55f8669d{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-19 08:51:27,160 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f92c349{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:51:27,164 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Shutting the HddsDatanodes
2019-09-19 08:51:27,164 [main] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-09-19 08:51:27,165 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(451)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@57fdb8a4
2019-09-19 08:51:27,208 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-09-19 08:51:27,801 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083/in_use.lock acquired by nodename 27083@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:51:30,105 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode e9620dcf-fbb8-43dd-90df-6386dfe78fe1{ip: 192.168.34.5, host: pr-hdds-1569-j4bt4-3030777008, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines []
2019-09-19 08:51:32,167 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-09-19 08:51:42,089 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083 has been successfully formatted.
2019-09-19 08:51:42,094 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-0C305E2DA083: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:51:42,095 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:51:42,098 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:51:42,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:51:42,106 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:51:42,108 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,115 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:51:42,122 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083
2019-09-19 08:51:42,138 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:51:42,138 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:51:42,143 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,143 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:51:42,144 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:51:42,144 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:51:42,145 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:51:42,145 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:51:42,146 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:51:42,154 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:51:42,541 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/56d3de99-d647-4da7-9f4a-0c305e2da083: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:51:42,549 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:51:42,551 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:51:42,551 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:51:42,587 [pool-27-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: remove     null group-0C305E2DA083 e9620dcf-fbb8-43dd-90df-6386dfe78fe1:t0, leader=null, voted=null, raftlog=e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null NEW
2019-09-19 08:51:42,588 [pool-27-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: Failed groupAdd* GroupManagementRequest:client-56F760AA0615->e9620dcf-fbb8-43dd-90df-6386dfe78fe1@group-0C305E2DA083, cid=0, seq=0, RW, null, Add:group-0C305E2DA083:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@1c6add9f rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@1c6add9f rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-09-19 08:51:42,593 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: new RaftServerImpl for group-F279671BCF98:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] with ContainerStateMachine:uninitialized
2019-09-19 08:51:42,593 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:51:42,593 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:51:42,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:51:42,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:51:42,594 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:51:42,594 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1:group-F279671BCF98 ConfigurationManager, init=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null, confs=<EMPTY_MAP>
2019-09-19 08:51:42,595 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis] (custom)
2019-09-19 08:51:42,595 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98 does not exist. Creating ...
2019-09-19 08:51:42,610 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98/in_use.lock acquired by nodename 27083@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:51:42,618 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98 has been successfully formatted.
2019-09-19 08:51:42,619 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F279671BCF98: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:51:42,619 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:51:42,619 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:51:42,619 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:51:42,620 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:51:42,620 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,620 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:51:42,620 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98
2019-09-19 08:51:42,621 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:51:42,621 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:51:42,621 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,621 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:51:42,622 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:51:42,622 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:51:42,622 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:51:42,622 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:51:42,622 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:51:42,623 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:51:42,623 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/545fca35-b6bf-4c9a-bc4b-f279671bcf98: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:51:42,623 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:51:42,624 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:51:42,624 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:51:42,624 [pool-27-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: remove     null group-F279671BCF98 e9620dcf-fbb8-43dd-90df-6386dfe78fe1:t0, leader=null, voted=null, raftlog=e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null NEW
2019-09-19 08:51:42,625 [pool-27-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: Failed groupAdd* GroupManagementRequest:client-167DAAAFE3FB->e9620dcf-fbb8-43dd-90df-6386dfe78fe1@group-F279671BCF98, cid=1, seq=0, RW, null, Add:group-F279671BCF98:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@2c3c53f0 rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@2c3c53f0 rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-09-19 08:51:42,628 [pool-27-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(93)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: new RaftServerImpl for group-AE48826E6C11:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578] with ContainerStateMachine:uninitialized
2019-09-19 08:51:42,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 5s (custom)
2019-09-19 08:51:42,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 5200ms (custom)
2019-09-19 08:51:42,629 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-09-19 08:51:42,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.sleep.deviation.threshold = 300 (default)
2019-09-19 08:51:42,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2019-09-19 08:51:42,630 [pool-27-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(105)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1:group-AE48826E6C11 ConfigurationManager, init=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null, confs=<EMPTY_MAP>
2019-09-19 08:51:42,630 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis] (custom)
2019-09-19 08:51:42,631 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11 does not exist. Creating ...
2019-09-19 08:51:42,643 [pool-27-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11/in_use.lock acquired by nodename 27083@pr-hdds-1569-j4bt4-3030777008
2019-09-19 08:51:42,650 [pool-27-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(72)) - Storage directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11 has been successfully formatted.
2019-09-19 08:51:42,650 [pool-27-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-AE48826E6C11: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.purge.gap = 1000000 (custom)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,651 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-09-19 08:51:42,652 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(172)) - new e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11 for RaftStorage:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11
2019-09-19 08:51:42,652 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-09-19 08:51:42,652 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-09-19 08:51:42,652 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 1048576 (custom)
2019-09-19 08:51:42,652 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-09-19 08:51:42,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-09-19 08:51:42,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-09-19 08:51:42,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-09-19 08:51:42,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-09-19 08:51:42,653 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-09-19 08:51:42,654 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-09-19 08:51:42,654 [pool-27-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(132)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLogWorker:Storage Directory /workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/ratis/596b26b8-fafa-41f5-a4eb-ae48826e6c11: flushIndex: setUnconditionally 0 -> -1
2019-09-19 08:51:42,654 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-09-19 08:51:42,654 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-09-19 08:51:42,655 [pool-27-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-09-19 08:51:42,655 [pool-27-thread-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:remove(95)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: remove     null group-AE48826E6C11 e9620dcf-fbb8-43dd-90df-6386dfe78fe1:t0, leader=null, voted=null, raftlog=e9620dcf-fbb8-43dd-90df-6386dfe78fe1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578], old=null NEW
2019-09-19 08:51:42,655 [pool-27-thread-1] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(388)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: Failed groupAdd* GroupManagementRequest:client-EDA6CC898999->e9620dcf-fbb8-43dd-90df-6386dfe78fe1@group-AE48826E6C11, cid=2, seq=0, RW, null, Add:group-AE48826E6C11:[e9620dcf-fbb8-43dd-90df-6386dfe78fe1:192.168.34.5:36578]
java.util.concurrent.CompletionException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@261bbe9c rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:604)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
	at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1595)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.CompletableFuture$UniApply@261bbe9c rejected from java.util.concurrent.ThreadPoolExecutor@511af0bb[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at java.util.concurrent.Executors$DelegatedExecutorService.execute(Executors.java:668)
	at java.util.concurrent.CompletableFuture$UniCompletion.claim(CompletableFuture.java:529)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:599)
	... 6 more
2019-09-19 08:51:42,657 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: close
2019-09-19 08:51:42,660 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(155)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: shutdown server with port 36578 now
2019-09-19 08:51:42,663 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(163)) - e9620dcf-fbb8-43dd-90df-6386dfe78fe1: shutdown server with port 36578 successfully
2019-09-19 08:51:42,666 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service BlockDeletingService
2019-09-19 08:51:42,670 [refreshUsed-/workdir/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a8165f31-c16d-47e6-9848-0f9393196f7b/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-09-19 08:51:42,692 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-09-19 08:51:43,587 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a08efdc{/,null,UNAVAILABLE}{/hddsDatanode}
2019-09-19 08:51:43,588 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@57272109{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:51:43,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66b59b7d{/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.5.0-SNAPSHOT/hadoop-hdds-container-service-0.5.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2019-09-19 08:51:43,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6edf29c1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:51:43,590 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(353)) - Stopping the StorageContainerManager
2019-09-19 08:51:43,591 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(797)) - Stopping Replication Manager Service.
2019-09-19 08:51:43,591 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(192)) - Stopping Replication Monitor Thread.
2019-09-19 08:51:43,591 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(804)) - Stopping Lease Manager of the command watchers
2019-09-19 08:51:43,591 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping datanode service RPC server
2019-09-19 08:51:43,592 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(367)) - Stopping the RPC server for DataNodes
2019-09-19 08:51:43,592 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33464
2019-09-19 08:51:43,593 [IPC Server listener on 33464] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33464
2019-09-19 08:51:43,594 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:51:43,633 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(655)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2019-09-19 08:51:43,634 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(819)) - Stopping block service RPC server
2019-09-19 08:51:43,634 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(148)) - Stopping the RPC server for Block Protocol
2019-09-19 08:51:43,634 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34951
2019-09-19 08:51:43,635 [IPC Server listener on 34951] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34951
2019-09-19 08:51:43,635 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(826)) - Stopping the StorageContainerLocationProtocol RPC server
2019-09-19 08:51:43,636 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:51:43,636 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(159)) - Stopping the RPC server for Client Protocol
2019-09-19 08:51:43,636 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42725
2019-09-19 08:51:43,637 [IPC Server listener on 42725] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42725
2019-09-19 08:51:43,637 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(833)) - Stopping Storage Container Manager HTTP server.
2019-09-19 08:51:43,638 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-09-19 08:51:43,639 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68e62ca4{/,null,UNAVAILABLE}{/scm}
2019-09-19 08:51:43,640 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d4960c8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-09-19 08:51:43,640 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64711bf2{/static,file:///workdir/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2019-09-19 08:51:43,640 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b1637e1{/logs,file:///workdir/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2019-09-19 08:51:43,642 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(844)) - Stopping Block Manager Service.
2019-09-19 08:51:43,642 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 08:51:43,642 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-09-19 08:51:43,643 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(866)) - Stopping SCM Event Queue.
2019-09-19 08:51:43,650 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2019-09-19 08:51:43,652 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
